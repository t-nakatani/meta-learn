{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nakatani/MetaLearning/hw1\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from scipy import misc\n",
    "import warnings\n",
    "from load_data import DataGenerator\n",
    "from tensorflow.python.platform import flags\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images(paths, labels, nb_samples=None, shuffle=True):\n",
    "    \"\"\"\n",
    "    Takes a set of character folders and labels and returns paths to image files\n",
    "    paired with labels.\n",
    "    Args:\n",
    "        paths: A list of character folders\n",
    "        labels: List or numpy array of same length as paths\n",
    "        nb_samples: Number of images to retrieve per character\n",
    "    Returns:\n",
    "        List of (label, image_path) tuples\n",
    "    \"\"\"\n",
    "    if nb_samples is not None:\n",
    "        sampler = lambda x: random.sample(x, nb_samples)\n",
    "    else:\n",
    "        sampler = lambda x: x\n",
    "    images_labels = [(i, os.path.join(path, image))\n",
    "                     for i, path in zip(labels, paths)\n",
    "                     for image in sampler(os.listdir(path))]\n",
    "    if shuffle:\n",
    "        random.shuffle(images_labels)\n",
    "    return images_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_file_to_array(filename, dim_input):\n",
    "    \"\"\"\n",
    "    Takes an image path and returns numpy array\n",
    "    Args:\n",
    "        filename: Image filename\n",
    "        dim_input: Flattened shape of image\n",
    "    Returns:\n",
    "        1 channel image\n",
    "    \"\"\"\n",
    "    image = misc.imread(filename)\n",
    "    image = image.reshape([dim_input])\n",
    "    image = image.astype(np.float32) / 255.0\n",
    "    image = 1.0 - image\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(object):\n",
    "    \"\"\"\n",
    "    Data Generator capable of generating batches of Omniglot data.\n",
    "    A \"class\" is considered a class of omniglot digits.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_classes, num_samples_per_class, config={}):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            num_classes: Number of classes for classification (K-way)\n",
    "            num_samples_per_class: num samples to generate per class in one batch\n",
    "            batch_size: size of meta batch size (e.g. number of functions)\n",
    "        \"\"\"\n",
    "        self.num_samples_per_class = num_samples_per_class\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        data_folder = config.get('data_folder', './omniglot_resized')\n",
    "        self.img_size = config.get('img_size', (28, 28))\n",
    "\n",
    "        self.dim_input = np.prod(self.img_size)\n",
    "        self.dim_output = self.num_classes\n",
    "        \n",
    "        #  this contains all character-paths\n",
    "        character_folders = [os.path.join(data_folder, family, character)\n",
    "                             for family in os.listdir(data_folder)\n",
    "                             if os.path.isdir(os.path.join(data_folder, family))\n",
    "                             for character in os.listdir(os.path.join(data_folder, family))\n",
    "                             if os.path.isdir(os.path.join(data_folder, family, character))]\n",
    "#         print(character_folders)\n",
    "\n",
    "        random.seed(1)\n",
    "        random.shuffle(character_folders)\n",
    "        num_val = 100\n",
    "        num_train = 1100\n",
    "        self.metatrain_character_folders = character_folders[: num_train]\n",
    "        self.metaval_character_folders = character_folders[\n",
    "            num_train:num_train + num_val]\n",
    "        self.metatest_character_folders = character_folders[\n",
    "            num_train + num_val:]\n",
    "\n",
    "    def sample_batch(self, batch_type, batch_size):\n",
    "        \"\"\"\n",
    "        Samples a batch for training, validation, or testing\n",
    "        Args:\n",
    "            batch_type: train/val/test\n",
    "        Returns:\n",
    "            A a tuple of (1) Image batch and (2) Label batch where\n",
    "            image batch has shape [B, K, N, 784] and label batch has shape [B, K, N, N]\n",
    "            where B is batch size, K is number of samples per class, N is number of classes\n",
    "        \"\"\"\n",
    "        if batch_type == \"train\":\n",
    "            folders = self.metatrain_character_folders\n",
    "        elif batch_type == \"val\":\n",
    "            folders = self.metaval_character_folders\n",
    "        else:\n",
    "            folders = self.metatest_character_folders\n",
    "\n",
    "        #############################\n",
    "        #### YOUR CODE GOES HERE ####\n",
    "        \n",
    "        B = batch_size\n",
    "        K = self.num_samples_per_class\n",
    "        N = self.num_classes\n",
    "        \n",
    "        all_image_batches = []\n",
    "        all_label_batches= []\n",
    "        \n",
    "        for b in range(B):\n",
    "            paths = random.sample(folders, N)\n",
    "            labels = paths + \"\"\n",
    "            images_labels = get_images(paths, labels, nb_samples=K, shuffle=False) # List of (label, image_path) tuples\n",
    "            ib3 = []\n",
    "            lb3 = []\n",
    "            for k in range(K):\n",
    "                i2 = []\n",
    "                lb2 = []\n",
    "                for n in range(N):\n",
    "                    tpl = img_lables[n*K+k]\n",
    "                    label ,filename = tpl                \n",
    "                    img_array = image_file_to_array(filename, 784)\n",
    "                    label_onehot = np.zeros(N - 1)\n",
    "                    if n == N-1: label_onehot.insert(-1,1)\n",
    "                    else: label_onehot.insert(n,1)\n",
    "                    ib2.append(img_array) # creating N * 784\n",
    "                    lb2.append(label_onehot)\n",
    "                ib3.append(ib2) # creating K * N * 784\n",
    "                lb3.append(lb2)\n",
    "            all_image_batches.append(ib3) # creating B * K * N * 784\n",
    "            all_label_batches.append(lb3) # creating B * K * N * N\n",
    "                \n",
    "                \n",
    "        #############################\n",
    "\n",
    "        return all_image_batches, all_label_batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "ename": "DuplicateFlagError",
     "evalue": "The flag 'num_classes' is defined twice. First from /Users/nakatani/.pyenv/versions/anaconda3-5.3.0/envs/meta/lib/python3.7/site-packages/ipykernel_launcher.py, Second from /Users/nakatani/.pyenv/versions/anaconda3-5.3.0/envs/meta/lib/python3.7/site-packages/ipykernel_launcher.py.  Description from first occurrence: number of classes used in classification (e.g. 5-way classification).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDuplicateFlagError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-135-6d9eb7e243ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m flags.DEFINE_integer(\n\u001b[0;32m----> 4\u001b[0;31m     'num_classes', 5, 'number of classes used in classification (e.g. 5-way classification).')\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m flags.DEFINE_integer('num_samples', 1,\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.0/envs/meta/lib/python3.7/site-packages/tensorflow/python/platform/flags.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m           \u001b[0;34m'Use of the keyword argument names (flag_name, default_value, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m           'docstring) is deprecated, please use (name, default, help) instead.')\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0moriginal_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_decorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.0/envs/meta/lib/python3.7/site-packages/absl/flags/_defines.py\u001b[0m in \u001b[0;36mDEFINE_integer\u001b[0;34m(name, default, help, lower_bound, upper_bound, flag_values, **args)\u001b[0m\n\u001b[1;32m    366\u001b[0m   \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_argument_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIntegerParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlower_bound\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupper_bound\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m   \u001b[0mserializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_argument_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mArgumentSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDEFINE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhelp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserializer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m   \u001b[0m_register_bounds_validator_if_needed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflag_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.0/envs/meta/lib/python3.7/site-packages/absl/flags/_defines.py\u001b[0m in \u001b[0;36mDEFINE\u001b[0;34m(parser, name, default, help, flag_values, serializer, module_name, **args)\u001b[0m\n\u001b[1;32m    101\u001b[0m   return DEFINE_flag(\n\u001b[1;32m    102\u001b[0m       \u001b[0m_flag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFlag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserializer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhelp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m       module_name)\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.0/envs/meta/lib/python3.7/site-packages/absl/flags/_defines.py\u001b[0m in \u001b[0;36mDEFINE_flag\u001b[0;34m(flag, flag_values, module_name)\u001b[0m\n\u001b[1;32m    126\u001b[0m   \u001b[0;31m# Copying the reference to flag_values prevents pychecker warnings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m   \u001b[0mfv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflag_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m   \u001b[0mfv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mflag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m   \u001b[0;31m# Tell flag_values who's defining the flag.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.0/envs/meta/lib/python3.7/site-packages/absl/flags/_flagvalues.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, name, flag)\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[0;31m# module is simply being imported a subsequent time.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0m_exceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDuplicateFlagError\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_flag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m     \u001b[0mshort_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshort_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[0;31m# If a new flag overrides an old one, we need to cleanup the old flag's\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDuplicateFlagError\u001b[0m: The flag 'num_classes' is defined twice. First from /Users/nakatani/.pyenv/versions/anaconda3-5.3.0/envs/meta/lib/python3.7/site-packages/ipykernel_launcher.py, Second from /Users/nakatani/.pyenv/versions/anaconda3-5.3.0/envs/meta/lib/python3.7/site-packages/ipykernel_launcher.py.  Description from first occurrence: number of classes used in classification (e.g. 5-way classification)."
     ]
    }
   ],
   "source": [
    "FLAGS = flags.FLAGS\n",
    "\n",
    "flags.DEFINE_integer(\n",
    "    'num_classes', 5, 'number of classes used in classification (e.g. 5-way classification).')\n",
    "\n",
    "flags.DEFINE_integer('num_samples', 1,\n",
    "                     'number of examples used for inner gradient update (K for K-shot learning).')\n",
    "\n",
    "flags.DEFINE_integer('meta_batch_size', 16,\n",
    "                     'Number of N-way classification tasks per batch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(preds, labels):\n",
    "    \"\"\"\n",
    "    Computes MANN loss\n",
    "    Args:\n",
    "        preds: [B, K+1, N, N] network output\n",
    "        labels: [B, K+1, N, N] labels\n",
    "    Returns:\n",
    "        scalar loss\n",
    "    \"\"\"\n",
    "    #############################\n",
    "    #### YOUR CODE GOES HERE ####\n",
    "    pass\n",
    "    #############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MANN(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, num_classes, samples_per_class):\n",
    "        super(MANN, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.samples_per_class = samples_per_class\n",
    "        self.layer1 = tf.keras.layers.LSTM(128, return_sequences=True)\n",
    "        self.layer2 = tf.keras.layers.LSTM(num_classes, return_sequences=True)\n",
    "\n",
    "    def call(self, input_images, input_labels):\n",
    "        \"\"\"\n",
    "        MANN\n",
    "        Args:\n",
    "            input_images: [B, K+1, N, 784] flattened images\n",
    "            labels: [B, K+1, N, N] ground truth labels\n",
    "        Returns:\n",
    "            [B, K+1, N, N] predictions\n",
    "        \"\"\"\n",
    "        #############################\n",
    "        #### YOUR CODE GOES HERE ####\n",
    "        pass\n",
    "        #############################\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnrecognizedFlagError",
     "evalue": "Unknown command line flag 'f'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnrecognizedFlagError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-133-f421e5b42597>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m ims = tf.placeholder(tf.float32, shape=(\n\u001b[0;32m----> 2\u001b[0;31m     None, FLAGS.num_samples + 1, FLAGS.num_classes, 784))\n\u001b[0m\u001b[1;32m      3\u001b[0m labels = tf.placeholder(tf.float32, shape=(\n\u001b[1;32m      4\u001b[0m     None, FLAGS.num_samples + 1, FLAGS.num_classes, FLAGS.num_classes))\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.0/envs/meta/lib/python3.7/site-packages/tensorflow/python/platform/flags.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;31m# a flag.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_parsed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m       \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.0/envs/meta/lib/python3.7/site-packages/absl/flags/_flagvalues.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, argv, known_only)\u001b[0m\n\u001b[1;32m    644\u001b[0m       \u001b[0msuggestions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_helpers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_flag_suggestions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m       raise _exceptions.UnrecognizedFlagError(\n\u001b[0;32m--> 646\u001b[0;31m           name, value, suggestions=suggestions)\n\u001b[0m\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmark_as_parsed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnrecognizedFlagError\u001b[0m: Unknown command line flag 'f'"
     ]
    }
   ],
   "source": [
    "ims = tf.placeholder(tf.float32, shape=(\n",
    "    None, FLAGS.num_samples + 1, FLAGS.num_classes, 784))\n",
    "labels = tf.placeholder(tf.float32, shape=(\n",
    "    None, FLAGS.num_samples + 1, FLAGS.num_classes, FLAGS.num_classes))\n",
    "\n",
    "data_generator = DataGenerator(\n",
    "    FLAGS.num_classes, FLAGS.num_samples + 1)\n",
    "\n",
    "o = MANN(FLAGS.num_classes, FLAGS.num_samples + 1)\n",
    "out = o(ims, labels)\n",
    "\n",
    "loss = loss_function(out, labels)\n",
    "optim = tf.train.AdamOptimizer(0.001)\n",
    "optimizer_step = optim.minimize(loss)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(50000):\n",
    "        i, l = data_generator.sample_batch('train', FLAGS.meta_batch_size)\n",
    "        feed = {ims: i.astype(np.float32), labels: l.astype(np.float32)}\n",
    "        _, ls = sess.run([optimizer_step, loss], feed)\n",
    "\n",
    "        if step % 100 == 0:\n",
    "            print(\"*\" * 5 + \"Iter \" + str(step) + \"*\" * 5)\n",
    "            i, l = data_generator.sample_batch('test', 100)\n",
    "            feed = {ims: i.astype(np.float32),\n",
    "                    labels: l.astype(np.float32)}\n",
    "            pred, tls = sess.run([out, loss], feed)\n",
    "            print(\"Train Loss:\", ls, \"Test Loss:\", tls)\n",
    "            pred = pred.reshape(\n",
    "                -1, FLAGS.num_samples + 1,\n",
    "                FLAGS.num_classes, FLAGS.num_classes)\n",
    "            pred = pred[:, -1, :, :].argmax(2)\n",
    "            l = l[:, -1, :, :].argmax(2)\n",
    "            print(\"Test Accuracy\", (1.0 * (pred == l)).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [i for i in range(5)]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2, 3, 4],\n",
       "       [0, 1, 2, 3, 4],\n",
       "       [0, 1, 2, 3, 4]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = np.array([a for i in range(3)])\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 5)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1, 2, 3, 4, 5],\n",
       "        [1, 2, 3, 4, 5],\n",
       "        [1, 2, 3, 4, 5]],\n",
       "\n",
       "       [[1, 2, 3, 4, 5],\n",
       "        [1, 2, 3, 4, 5],\n",
       "        [1, 2, 3, 4, 5]],\n",
       "\n",
       "       [[1, 2, 3, 4, 5],\n",
       "        [1, 2, 3, 4, 5],\n",
       "        [1, 2, 3, 4, 5]],\n",
       "\n",
       "       [[1, 2, 3, 4, 5],\n",
       "        [1, 2, 3, 4, 5],\n",
       "        [1, 2, 3, 4, 5]]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs = np.array([[[i+1 for i in range(5)] for j in range(3)] for k in range(4)])\n",
    "imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 3, 5)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs.shape\n",
    "# 5 by 3 img * 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 2\n",
    "c = np.array([[b for i in range(3)] for j in range(B)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, 3, 5)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[0, 1, 2, 3, 4],\n",
       "         [0, 1, 2, 3, 4],\n",
       "         [0, 1, 2, 3, 4]],\n",
       " \n",
       "        [[0, 1, 2, 3, 4],\n",
       "         [0, 1, 2, 3, 4],\n",
       "         [0, 1, 2, 3, 4]],\n",
       " \n",
       "        [[0, 1, 2, 3, 4],\n",
       "         [0, 1, 2, 3, 4],\n",
       "         [0, 1, 2, 3, 4]]]),\n",
       " array([[[0, 1, 2, 3, 4],\n",
       "         [0, 1, 2, 3, 4],\n",
       "         [0, 1, 2, 3, 4]],\n",
       " \n",
       "        [[0, 1, 2, 3, 4],\n",
       "         [0, 1, 2, 3, 4],\n",
       "         [0, 1, 2, 3, 4]],\n",
       " \n",
       "        [[0, 1, 2, 3, 4],\n",
       "         [0, 1, 2, 3, 4],\n",
       "         [0, 1, 2, 3, 4]]])]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = (random.sample(list(c), 2))\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, 3, 5)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(d).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'character_folders' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-115-420e8b5532f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcharacter_folders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'character_folders' is not defined"
     ]
    }
   ],
   "source": [
    "character_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_folder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-116-135fac43e82b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data_folder' is not defined"
     ]
    }
   ],
   "source": [
    "data_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = DataGenerator(\n",
    "    5, 1 + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataGenerator' object has no attribute 'character_folders'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-118-5d0d877efa0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcharacter_folders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataGenerator' object has no attribute 'character_folders'"
     ]
    }
   ],
   "source": [
    "data_generator.character_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'filename' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-119-6d9944920313>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mimage_file_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m784\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'filename' is not defined"
     ]
    }
   ],
   "source": [
    "# def image_file_to_array(filename, dim_input):\n",
    "\n",
    "\n",
    "image_file_to_array(filename, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = (1,2)\n",
    "f1, f2  = f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_images(paths, labels, nb_samples=None, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n",
      "[[1], [2]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ii = [1]\n",
    "mm = [2]\n",
    "listtt = []\n",
    "listtt.append(ii)\n",
    "print(listtt)\n",
    "listtt.append(mm)\n",
    "print(listtt)\n",
    "np.array(listtt).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = [(i, j) for i in range(5) for j in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0),\n",
       " (0, 1),\n",
       " (0, 2),\n",
       " (0, 3),\n",
       " (1, 0),\n",
       " (1, 1),\n",
       " (1, 2),\n",
       " (1, 3),\n",
       " (2, 0),\n",
       " (2, 1),\n",
       " (2, 2),\n",
       " (2, 3),\n",
       " (3, 0),\n",
       " (3, 1),\n",
       " (3, 2),\n",
       " (3, 3),\n",
       " (4, 0),\n",
       " (4, 1),\n",
       " (4, 2),\n",
       " (4, 3)]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nakatani/.pyenv/versions/anaconda3-5.3.0/envs/meta/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/nakatani/.pyenv/versions/anaconda3-5.3.0/envs/meta/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/nakatani/.pyenv/versions/anaconda3-5.3.0/envs/meta/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/nakatani/.pyenv/versions/anaconda3-5.3.0/envs/meta/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/nakatani/.pyenv/versions/anaconda3-5.3.0/envs/meta/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/nakatani/.pyenv/versions/anaconda3-5.3.0/envs/meta/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/nakatani/.pyenv/versions/anaconda3-5.3.0/envs/meta/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/nakatani/.pyenv/versions/anaconda3-5.3.0/envs/meta/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/nakatani/.pyenv/versions/anaconda3-5.3.0/envs/meta/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/nakatani/.pyenv/versions/anaconda3-5.3.0/envs/meta/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/nakatani/.pyenv/versions/anaconda3-5.3.0/envs/meta/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/nakatani/.pyenv/versions/anaconda3-5.3.0/envs/meta/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "WARNING:tensorflow:From hw1.py:74: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/nakatani/.pyenv/versions/anaconda3-5.3.0/envs/meta/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:Entity <bound method MANN.call of <__main__.MANN object at 0x7fc9ba481910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MANN.call of <__main__.MANN object at 0x7fc9ba481910>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:From hw1.py:33: The name tf.losses.softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/nakatani/.pyenv/versions/anaconda3-5.3.0/envs/meta/lib/python3.7/site-packages/tensorflow/python/ops/losses/losses_impl.py:121: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From hw1.py:86: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From hw1.py:89: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "2020-10-26 18:36:18.550523: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-10-26 18:36:18.551107: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 12. Tune using inter_op_parallelism_threads for best performance.\n",
      "WARNING:tensorflow:From hw1.py:90: The name tf.local_variables_initializer is deprecated. Please use tf.compat.v1.local_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From hw1.py:91: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "*****Iter 0*****\n",
      "Train Loss: 0.6932375 Test Loss: 0.69878924\n",
      "Test Accuracy 0.495\n",
      "*****Iter 100*****\n",
      "Train Loss: 0.7013693 Test Loss: 0.6931511\n",
      "Test Accuracy 0.49\n",
      "*****Iter 200*****\n",
      "Train Loss: 0.692635 Test Loss: 0.6947373\n",
      "Test Accuracy 0.445\n",
      "*****Iter 300*****\n",
      "Train Loss: 0.68101996 Test Loss: 0.6884591\n",
      "Test Accuracy 0.565\n",
      "*****Iter 400*****\n",
      "Train Loss: 0.68539834 Test Loss: 0.69216204\n",
      "Test Accuracy 0.52\n",
      "*****Iter 500*****\n",
      "Train Loss: 0.6911504 Test Loss: 0.6912634\n",
      "Test Accuracy 0.56\n",
      "*****Iter 600*****\n",
      "Train Loss: 0.69286925 Test Loss: 0.69421506\n",
      "Test Accuracy 0.44\n",
      "*****Iter 700*****\n",
      "Train Loss: 0.69353706 Test Loss: 0.6928241\n",
      "Test Accuracy 0.525\n",
      "*****Iter 800*****\n",
      "Train Loss: 0.6932001 Test Loss: 0.693013\n",
      "Test Accuracy 0.51\n",
      "*****Iter 900*****\n",
      "Train Loss: 0.69276524 Test Loss: 0.69318753\n",
      "Test Accuracy 0.44\n",
      "*****Iter 1000*****\n",
      "Train Loss: 0.69303894 Test Loss: 0.6932843\n",
      "Test Accuracy 0.495\n",
      "*****Iter 1100*****\n",
      "Train Loss: 0.6931472 Test Loss: 0.693001\n",
      "Test Accuracy 0.51\n",
      "*****Iter 1200*****\n",
      "Train Loss: 0.6931472 Test Loss: 0.69311684\n",
      "Test Accuracy 0.495\n",
      "*****Iter 1300*****\n",
      "Train Loss: 0.6932156 Test Loss: 0.6928679\n",
      "Test Accuracy 0.51\n",
      "*****Iter 1400*****\n",
      "Train Loss: 0.692182 Test Loss: 0.6931002\n",
      "Test Accuracy 0.515\n",
      "*****Iter 1500*****\n",
      "Train Loss: 0.6931472 Test Loss: 0.6932304\n",
      "Test Accuracy 0.51\n",
      "*****Iter 1600*****\n",
      "Train Loss: 0.6931492 Test Loss: 0.6930621\n",
      "Test Accuracy 0.495\n",
      "*****Iter 1700*****\n",
      "Train Loss: 0.6931472 Test Loss: 0.69308\n",
      "Test Accuracy 0.47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Iter 1800*****\n",
      "Train Loss: 0.6931472 Test Loss: 0.69313246\n",
      "Test Accuracy 0.495\n",
      "*****Iter 1900*****\n",
      "Train Loss: 0.6931472 Test Loss: 0.69314873\n",
      "Test Accuracy 0.49\n",
      "*****Iter 2000*****\n",
      "Train Loss: 0.6931472 Test Loss: 0.69315237\n",
      "Test Accuracy 0.485\n",
      "*****Iter 2100*****\n",
      "Train Loss: 0.6931472 Test Loss: 0.6931436\n",
      "Test Accuracy 0.51\n",
      "*****Iter 2200*****\n",
      "Train Loss: 0.6931472 Test Loss: 0.69314766\n",
      "Test Accuracy 0.495\n",
      "*****Iter 2300*****\n",
      "Train Loss: 0.6931472 Test Loss: 0.69314605\n",
      "Test Accuracy 0.5\n",
      "*****Iter 2400*****\n",
      "Train Loss: 0.6931378 Test Loss: 0.693154\n",
      "Test Accuracy 0.495\n",
      "*****Iter 2500*****\n",
      "Train Loss: 0.6931472 Test Loss: 0.693045\n",
      "Test Accuracy 0.485\n",
      "*****Iter 2600*****\n",
      "Train Loss: 0.6931472 Test Loss: 0.6931466\n",
      "Test Accuracy 0.505\n",
      "*****Iter 2700*****\n",
      "Train Loss: 0.6931472 Test Loss: 0.6931474\n",
      "Test Accuracy 0.5\n",
      "*****Iter 2800*****\n",
      "Train Loss: 0.6931472 Test Loss: 0.6931441\n",
      "Test Accuracy 0.49\n",
      "*****Iter 2900*****\n",
      "Train Loss: 0.6931472 Test Loss: 0.69315606\n",
      "Test Accuracy 0.49\n",
      "*****Iter 3000*****\n",
      "Train Loss: 0.6931509 Test Loss: 0.69314\n",
      "Test Accuracy 0.5\n",
      "*****Iter 3100*****\n",
      "Train Loss: 0.6931472 Test Loss: 0.6931463\n",
      "Test Accuracy 0.515\n",
      "*****Iter 3200*****\n",
      "Train Loss: 0.6931472 Test Loss: 0.6931494\n",
      "Test Accuracy 0.5\n",
      "*****Iter 3300*****\n",
      "Train Loss: 0.6931472 Test Loss: 0.6931523\n",
      "Test Accuracy 0.495\n",
      "*****Iter 3400*****\n",
      "Train Loss: 0.6931472 Test Loss: 0.6931474\n",
      "Test Accuracy 0.5\n",
      "*****Iter 3500*****\n",
      "Train Loss: 0.6931472 Test Loss: 0.6931461\n",
      "Test Accuracy 0.505\n",
      "*****Iter 3600*****\n",
      "Train Loss: 0.6931472 Test Loss: 0.693149\n",
      "Test Accuracy 0.495\n",
      "*****Iter 3700*****\n",
      "Train Loss: 0.6931472 Test Loss: 0.6932144\n",
      "Test Accuracy 0.495\n",
      "*****Iter 3800*****\n",
      "Train Loss: 0.6931472 Test Loss: 0.6931474\n",
      "Test Accuracy 0.5\n",
      "*****Iter 3900*****\n",
      "Train Loss: 0.6931472 Test Loss: 0.69314283\n",
      "Test Accuracy 0.505\n",
      "*****Iter 4000*****\n",
      "Train Loss: 0.6931472 Test Loss: 0.6931475\n",
      "Test Accuracy 0.49\n",
      "*****Iter 4100*****\n",
      "Train Loss: 0.6931472 Test Loss: 0.69313586\n",
      "Test Accuracy 0.5\n",
      "*****Iter 4200*****\n",
      "Train Loss: 0.6931472 Test Loss: 0.6931461\n",
      "Test Accuracy 0.5\n",
      "*****Iter 4300*****\n",
      "Train Loss: 0.6931472 Test Loss: 0.6931474\n",
      "Test Accuracy 0.495\n",
      "*****Iter 4400*****\n",
      "Train Loss: 0.6931472 Test Loss: 0.6931474\n",
      "Test Accuracy 0.495\n",
      "*****Iter 4500*****\n",
      "Train Loss: 0.6931472 Test Loss: 0.6931474\n",
      "Test Accuracy 0.5\n",
      "*****Iter 4600*****\n",
      "Train Loss: 0.6931472 Test Loss: 0.6931474\n",
      "Test Accuracy 0.505\n",
      "*****Iter 4700*****\n",
      "Train Loss: 0.6931472 Test Loss: 0.6931474\n",
      "Test Accuracy 0.5\n",
      "*****Iter 4800*****\n",
      "Train Loss: 0.6931472 Test Loss: 0.6931476\n",
      "Test Accuracy 0.495\n",
      "*****Iter 4900*****\n",
      "Train Loss: 0.6931472 Test Loss: 0.6931474\n",
      "Test Accuracy 0.5\n",
      "*****Iter 5000*****\n",
      "Train Loss: 0.6931472 Test Loss: 0.69314796\n",
      "Test Accuracy 0.49\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"hw1.py\", line 96, in <module>\n",
      "    _, ls = sess.run([optimizer_step, loss], feed)\n",
      "  File \"/Users/nakatani/.pyenv/versions/anaconda3-5.3.0/envs/meta/lib/python3.7/site-packages/tensorflow/python/client/session.py\", line 950, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/Users/nakatani/.pyenv/versions/anaconda3-5.3.0/envs/meta/lib/python3.7/site-packages/tensorflow/python/client/session.py\", line 1173, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/Users/nakatani/.pyenv/versions/anaconda3-5.3.0/envs/meta/lib/python3.7/site-packages/tensorflow/python/client/session.py\", line 1350, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/Users/nakatani/.pyenv/versions/anaconda3-5.3.0/envs/meta/lib/python3.7/site-packages/tensorflow/python/client/session.py\", line 1356, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/Users/nakatani/.pyenv/versions/anaconda3-5.3.0/envs/meta/lib/python3.7/site-packages/tensorflow/python/client/session.py\", line 1341, in _run_fn\n",
      "    options, feed_dict, fetch_list, target_list, run_metadata)\n",
      "  File \"/Users/nakatani/.pyenv/versions/anaconda3-5.3.0/envs/meta/lib/python3.7/site-packages/tensorflow/python/client/session.py\", line 1429, in _call_tf_sessionrun\n",
      "    run_metadata)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python hw1.py --num_classes=2 --num_samples=1 --meta_batch_size=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='TRUE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /Users/nakatani/.pyenv/versions/anaconda3-5.3.0/envs/meta\n",
      "\n",
      "  added / updated specs:\n",
      "    - pillow\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    freetype-2.10.4            |       ha233b18_0         891 KB\n",
      "    lcms2-2.11                 |       h92f6f08_0         385 KB\n",
      "    libtiff-4.1.0              |       hcb84e12_1         512 KB\n",
      "    lz4-c-1.9.2                |       h79c402e_3         152 KB\n",
      "    pillow-8.0.0               |   py37h1a82f1a_0         648 KB\n",
      "    zstd-1.4.5                 |       h41d2c2f_0         1.0 MB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         3.5 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  freetype           pkgs/main/osx-64::freetype-2.10.4-ha233b18_0\n",
      "  lcms2              pkgs/main/osx-64::lcms2-2.11-h92f6f08_0\n",
      "  libtiff            pkgs/main/osx-64::libtiff-4.1.0-hcb84e12_1\n",
      "  lz4-c              pkgs/main/osx-64::lz4-c-1.9.2-h79c402e_3\n",
      "  olefile            pkgs/main/osx-64::olefile-0.46-py37_0\n",
      "  pillow             pkgs/main/osx-64::pillow-8.0.0-py37h1a82f1a_0\n",
      "  zstd               pkgs/main/osx-64::zstd-1.4.5-h41d2c2f_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "lcms2-2.11           | 385 KB    | ##################################### | 100% \n",
      "pillow-8.0.0         | 648 KB    | ##################################### | 100% \n",
      "zstd-1.4.5           | 1.0 MB    | ##################################### | 100% \n",
      "lz4-c-1.9.2          | 152 KB    | ##################################### | 100% \n",
      "libtiff-4.1.0        | 512 KB    | ##################################### | 100% \n",
      "freetype-2.10.4      | 891 KB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "!conda install pillow -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.1.0'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [0]*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /Users/nakatani/.pyenv/versions/anaconda3-5.3.0/envs/meta\n",
      "\n",
      "  added / updated specs:\n",
      "    - scikit-learn\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    joblib-0.17.0              |             py_0         205 KB\n",
      "    llvm-openmp-10.0.0         |       h28b9765_0         270 KB\n",
      "    scikit-learn-0.23.2        |   py37h959d312_0         6.3 MB\n",
      "    threadpoolctl-2.1.0        |     pyh5ca1d4c_0          16 KB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         6.8 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  joblib             pkgs/main/noarch::joblib-0.17.0-py_0\n",
      "  llvm-openmp        pkgs/main/osx-64::llvm-openmp-10.0.0-h28b9765_0\n",
      "  scikit-learn       pkgs/main/osx-64::scikit-learn-0.23.2-py37h959d312_0\n",
      "  threadpoolctl      pkgs/main/noarch::threadpoolctl-2.1.0-pyh5ca1d4c_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "llvm-openmp-10.0.0   | 270 KB    | ##################################### | 100% \n",
      "scikit-learn-0.23.2  | 6.3 MB    | ##################################### | 100% \n",
      "threadpoolctl-2.1.0  | 16 KB     | ##################################### | 100% \n",
      "joblib-0.17.0        | 205 KB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "!conda install scikit-learn -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
